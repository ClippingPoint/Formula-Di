{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# From Alex Staravoitau\n",
    "# https://github.com/navoshta/KITTI-Dataset/blob/master/kitti-dataset.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pykitti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "basedir = 'data/'\n",
    "\n",
    "date = '2011_09_26'\n",
    "drive = '0002'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_dataset(date, drive, calibrated=False, frame_range=None):\n",
    "    \"\"\"\n",
    "    Loads the dataset with `date` and `drive`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    date        : Dataset creation date.\n",
    "    drive       : Dataset drive.\n",
    "    calibrated  : Flag indicating if we need to parse calibration data. Defaults to `False`.\n",
    "    frame_range : Range of frames. Defaults to `None`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Loaded dataset of type `raw`.\n",
    "    \"\"\"\n",
    "    dataset = pykitti.raw(basedir, date, drive)\n",
    "\n",
    "    # Load the data\n",
    "    if calibrated:\n",
    "        dataset.load_calib()  # Calibration data are accessible as named tuples\n",
    "    dataset.load_timestamps()  # Timestamps are parsed into datetime objects\n",
    "    dataset.load_oxts()  # OXTS packets are loaded as named tuples\n",
    "    dataset.load_gray()  # Left/right images are accessible as named tuples\n",
    "    dataset.load_rgb()  # Left/right images are accessible as named tuples\n",
    "    dataset.load_velo()  # Each scan is a Nx4 array of [x,y,z,reflectance]\n",
    "\n",
    "    np.set_printoptions(precision=4, suppress=True)\n",
    "    print('\\nDrive: ' + str(dataset.drive))\n",
    "    print('\\nFrame range: ' + str(dataset.frame_range))\n",
    "\n",
    "    if calibrated:\n",
    "        print('\\nIMU-to-Velodyne transformation:\\n' + str(dataset.calib.T_velo_imu))\n",
    "        print('\\nGray stereo pair baseline [m]: ' + str(dataset.calib.b_gray))\n",
    "        print('\\nRGB stereo pair baseline [m]: ' + str(dataset.calib.b_rgb))\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading OXTS timestamps from 2011_09_26_drive_0002_sync...\n",
      "Found 77 timestamps...\n",
      "done.\n",
      "Loading OXTS data from 2011_09_26_drive_0002_sync...\n",
      "Found 77 OXTS measurements...\n",
      "done.\n",
      "Loading monochrome images from 2011_09_26_drive_0002_sync...\n",
      "Found 77 image pairs...\n",
      "done.\n",
      "Loading color images from 2011_09_26_drive_0002_sync...\n",
      "Found 77 image pairs...\n",
      "done.\n",
      "Found 77 Velodyne scans...\n",
      "done.\n",
      "\n",
      "Drive: 2011_09_26_drive_0002_sync\n",
      "\n",
      "Frame range: None\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(date, drive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import parseTrackletXML as xmlParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_tracklets_for_frames(n_frames, xml_path):\n",
    "    \"\"\"\n",
    "    Loads dataset labels also referred to as tracklets, saving them individually for each frame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_frames    : Number of frames in the dataset.\n",
    "    xml_path    : Path to the tracklets XML.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple of dictionaries with integer keys corresponding to absolute frame numbers and arrays as values. First array\n",
    "    contains coordinates of bounding box vertices for each object in the frame, and the second array contains objects\n",
    "    types as strings.\n",
    "    \"\"\"\n",
    "    tracklets = xmlParser.parseXML(xml_path)\n",
    "\n",
    "    frame_tracklets = {}\n",
    "    frame_tracklets_types = {}\n",
    "    for i in range(n_frames):\n",
    "        frame_tracklets[i] = []\n",
    "        frame_tracklets_types[i] = []\n",
    "\n",
    "    # loop over tracklets\n",
    "    for i, tracklet in enumerate(tracklets):\n",
    "        # this part is inspired by kitti object development kit matlab code: computeBox3D\n",
    "        h, w, l = tracklet.size\n",
    "        # in velodyne coordinates around zero point and without orientation yet\n",
    "        trackletBox = np.array([\n",
    "            [-l / 2, -l / 2, l / 2, l / 2, -l / 2, -l / 2, l / 2, l / 2],\n",
    "            [w / 2, -w / 2, -w / 2, w / 2, w / 2, -w / 2, -w / 2, w / 2],\n",
    "            [0.0, 0.0, 0.0, 0.0, h, h, h, h]\n",
    "        ])\n",
    "        # loop over all data in tracklet\n",
    "        for translation, rotation, state, occlusion, truncation, amtOcclusion, amtBorders, absoluteFrameNumber in tracklet:\n",
    "            # determine if object is in the image; otherwise continue\n",
    "            if truncation not in (xmlParser.TRUNC_IN_IMAGE, xmlParser.TRUNC_TRUNCATED):\n",
    "                continue\n",
    "            # re-create 3D bounding box in velodyne coordinate system\n",
    "            yaw = rotation[2]  # other rotations are supposedly 0\n",
    "            assert np.abs(rotation[:2]).sum() == 0, 'object rotations other than yaw given!'\n",
    "            rotMat = np.array([\n",
    "                [np.cos(yaw), -np.sin(yaw), 0.0],\n",
    "                [np.sin(yaw), np.cos(yaw), 0.0],\n",
    "                [0.0, 0.0, 1.0]\n",
    "            ])\n",
    "            cornerPosInVelo = np.dot(rotMat, trackletBox) + np.tile(translation, (8, 1)).T\n",
    "            frame_tracklets[absoluteFrameNumber] = frame_tracklets[absoluteFrameNumber] + [cornerPosInVelo]\n",
    "            frame_tracklets_types[absoluteFrameNumber] = frame_tracklets_types[absoluteFrameNumber] + [\n",
    "                tracklet.objectType]\n",
    "\n",
    "    return (frame_tracklets, frame_tracklets_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsing tracklet file data/2011_09_26/2011_09_26_drive_0002_sync/tracklet_labels.xml\n",
      "file contains 3 tracklets\n",
      "loaded 3 tracklets\n"
     ]
    }
   ],
   "source": [
    "tracklet_rects, tracklet_types = load_tracklets_for_frames(len(dataset.velo), 'data/{}/{}_drive_{}_sync/tracklet_labels.xml'.format(date, date, drive))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77,)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(np.array(dataset.velo).shape)\n",
    "print(len(tracklet_rects[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colors = {\n",
    "    'Car': 'b',\n",
    "    'Tram': 'r',\n",
    "    'Cyclist': 'g',\n",
    "    'Van': 'c',\n",
    "    'Truck': 'm',\n",
    "    'Pedestrain': 'y',\n",
    "    'Sitter': 'k'\n",
    "}\n",
    "axes_limits = [\n",
    "    [-40, 80], # X axis range\n",
    "    [-20, 20], # Y axis range\n",
    "    [-3, 10], # Z axis range\n",
    "]\n",
    "axes_str = ['X', 'Y', 'Z']\n",
    "def draw_box(pyplot_axis, vertices, axes=[0, 1, 2], color='black'):\n",
    "    \"\"\"\n",
    "    Draws a bounding 3D box in a pyplot axis.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    pyplot_axis : Pyplot axis to draw in.\n",
    "    vertices    : Array 8 box vertices containing x, y, z coordinates.\n",
    "    axes        : Axes to use. Defaults to `[0, 1, 2]`, e.g. x, y and z axes.\n",
    "    color       : Drawing color. Defaults to `black`.\n",
    "    \"\"\"\n",
    "    vertices = vertices[axes, :]\n",
    "    connections = [\n",
    "        [0, 1], [1, 2], [2, 3], [3, 0],  # Lower plane parallel to Z=0 plane\n",
    "        [4, 5], [5, 6], [6, 7], [7, 4],  # Upper plane parallel to Z=0 plane\n",
    "        [0, 4], [1, 5], [2, 6], [3, 7]  # Connections between upper and lower planes\n",
    "    ]\n",
    "    for connection in connections:\n",
    "        pyplot_axis.plot(*vertices[:, connection], c=color, lw=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_frame_statistics(dataset, tracklet_rects, tracklet_types, frame, points=0.2):\n",
    "    \"\"\"\n",
    "    Displays statistics for a single frame. Draws camera data, 3D plot of the lidar point cloud data and point cloud\n",
    "    projections to various planes.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset         : `raw` dataset.\n",
    "    tracklet_rects  : Dictionary with tracklet bounding boxes coordinates.\n",
    "    tracklet_types  : Dictionary with tracklet types.\n",
    "    frame           : Absolute number of the frame.\n",
    "    points          : Fraction of lidar points to use. Defaults to `0.2`, e.g. 20%.\n",
    "    \"\"\"\n",
    "            \n",
    "    print('Frame timestamp: ' + str(dataset.timestamps[frame]))\n",
    "    # Draw camera data\n",
    "    f, ax = plt.subplots(2, 2, figsize=(15, 5))\n",
    "    ax[0, 0].imshow(dataset.gray[frame].left, cmap='gray')\n",
    "    ax[0, 0].set_title('Left Gray Image (cam0)')\n",
    "    ax[0, 1].imshow(dataset.gray[frame].right, cmap='gray')\n",
    "    ax[0, 1].set_title('Right Gray Image (cam1)')\n",
    "    ax[1, 0].imshow(dataset.rgb[frame].left)\n",
    "    ax[1, 0].set_title('Left RGB Image (cam2)')\n",
    "    ax[1, 1].imshow(dataset.rgb[frame].right)\n",
    "    ax[1, 1].set_title('Right RGB Image (cam3)')\n",
    "    plt.show()\n",
    "\n",
    "    points_step = int(1. / points)\n",
    "    point_size = 0.01 * (1. / points)\n",
    "    velo_range = range(0, dataset.velo[frame].shape[0], points_step)\n",
    "    velo_frame = dataset.velo[frame][velo_range, :]      \n",
    "    def draw_point_cloud(ax, title, axes=[0, 1, 2]):\n",
    "        \"\"\"\n",
    "        Convenient method for drawing various point cloud projections as a part of frame statistics.\n",
    "        \"\"\"\n",
    "        ax.scatter(*np.transpose(velo_frame[:, axes]), s=point_size, c=velo_frame[:, 3], cmap='gray')\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel('{} axis'.format(axes_str[axes[0]]))\n",
    "        ax.set_ylabel('{} axis'.format(axes_str[axes[1]]))\n",
    "        if len(axes) > 2:\n",
    "            ax.set_xlim3d(*axes_limits[axes[0]])\n",
    "            ax.set_ylim3d(*axes_limits[axes[1]])\n",
    "            ax.set_zlim3d(*axes_limits[axes[2]])\n",
    "            ax.set_zlabel('{} axis'.format(axes_str[axes[2]]))\n",
    "        else:\n",
    "            ax.set_xlim(*axes_limits[axes[0]])\n",
    "            ax.set_ylim(*axes_limits[axes[1]])              \n",
    "        for t_rects, t_type in zip(tracklet_rects[frame], tracklet_types[frame]):\n",
    "            draw_box(ax, t_rects, axes=axes, color=colors[t_type])\n",
    "            \n",
    "    # Draw point cloud data as 3D plot\n",
    "    f2 = plt.figure(figsize=(15, 8))\n",
    "    ax2 = f2.add_subplot(111, projection='3d')                    \n",
    "    draw_point_cloud(ax2, 'Velodyne scan')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'frame' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-8d6f780d0d31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mFrame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdisplay_frame_statistics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracklet_rects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracklet_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'frame' is not defined"
     ]
    }
   ],
   "source": [
    "frame = 20\n",
    "display_frame_statistics(dataset, tracklet_rects, tracklet_types, frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing animation frames...\n",
      " |█████-----------------------------------------------------------------------------------------------| 5.3% "
     ]
    }
   ],
   "source": [
    "# from source.utilities import print_progress\n",
    "from moviepy.editor import ImageSequenceClip\n",
    "from utilities import print_progress\n",
    "def draw_3d_plot(frame, dataset, tracklet_rects, tracklet_types, points=0.2):\n",
    "    \"\"\"\n",
    "    Saves a single frame for an animation: a 3D plot of the lidar data without ticks and all frame trackelts.\n",
    "    Parameters\n",
    "    ----------\n",
    "    frame           : Absolute number of the frame.\n",
    "    dataset         : `raw` dataset.\n",
    "    tracklet_rects  : Dictionary with tracklet bounding boxes coordinates.\n",
    "    tracklet_types  : Dictionary with tracklet types.\n",
    "    points          : Fraction of lidar points to use. Defaults to `0.2`, e.g. 20%.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Saved frame filename.\n",
    "    \"\"\"\n",
    "    f = plt.figure(figsize=(12, 8))\n",
    "    axis = f.add_subplot(111, projection='3d', xticks=[], yticks=[], zticks=[])\n",
    "\n",
    "    points_step = int(1. / points)\n",
    "    point_size = 0.01 * (1. / points)\n",
    "    velo_range = range(0, dataset.velo[frame].shape[0], points_step)\n",
    "    velo_frame = dataset.velo[frame][velo_range, :]\n",
    "    axis.scatter(*np.transpose(velo_frame[:, [0, 1, 2]]), s=point_size, c=velo_frame[:, 3], cmap='gray')\n",
    "    axis.set_xlim3d(*axes_limits[0])\n",
    "    axis.set_ylim3d(*axes_limits[1])\n",
    "    axis.set_zlim3d(*axes_limits[2])\n",
    "    for t_rects, t_type in zip(tracklet_rects[frame], tracklet_types[frame]):\n",
    "        draw_box(axis, t_rects, axes=[0, 1, 2], color=colors[t_type])\n",
    "    filename = 'video/frame_{0:0>4}.png'.format(frame)\n",
    "    plt.savefig(filename)\n",
    "    plt.close(f)\n",
    "    return filename\n",
    "\n",
    "frames = []\n",
    "n_frames = len(dataset.velo)\n",
    "\n",
    "print('Preparing animation frames...')\n",
    "for i in range(n_frames):\n",
    "    print_progress(i, n_frames - 1)\n",
    "    filename = draw_3d_plot(i, dataset, tracklet_rects, tracklet_types)\n",
    "    frames += [filename]\n",
    "print('...Animation frames ready.')\n",
    "\n",
    "clip = ImageSequenceClip(frames, fps=5)\n",
    "% time\n",
    "clip.write_gif('pcl_data.gif', fps=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
